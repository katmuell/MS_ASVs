---
title: "DADA2"
output: html_document
---

#Load Libraries
```{r}
library(readr)
library(fs)
library(tibble)
library(Biostrings)
library(dada2)
library(stringr)
library(magrittr)
library(ggplot2)
library(tidyr)
library(phyloseq)
```

#Setup
Set up paths and directories
```{r}
#Directories
data.dir = "/work/kdm65/"
demux.dir = "/work/kdm65/MS"
output.dir = "/work/kdm65/scratch"

#Files
map.file = file.path(data.dir, "MS_map.txt")
silva.ref = file.path(data.dir, "silva_nr99_v138.1_wSpecies_train_set.fa.gz")
ps.rds = file.path(output.dir, "MS.rds")
```

#Filter and Trim
Get lists of forward and reverse reads
```{r}
fnFs <- sort(list.files(demux.dir, pattern = "_1.fastq", full.names = TRUE))
fnRs <- sort(list.files(demux.dir, pattern = "_2.fastq", full.names = TRUE))

forward_fastq_suffix = "_1.fastq.gz"

fnFs %>%
  basename %>%
  str_replace(forward_fastq_suffix, "") ->
  sample.names
```

```{r}
print(fnFs)
```

```{r}
print(fnRs)
```

```{r}
print(sample.names)
```

#Quality Profiles
```{r}
plotQualityProfile(fnFs[1:2])
```

```{r}
plotQualityProfile(fnRs[1:2])
```

#Filter Reads
Assign filepaths for filtered reads
```{r}
filt_path <- file.path(output.dir, "filtered")
filtFs <- file.path(filt_path, paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(filt_path, paste0(sample.names, "_R_filt.fastq.gz"))
```

Filter reads
```{r}
filt.out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, trimLeft = 10, truncLen = c(190, 150),
                          maxN = 0, maxEE = c(2,2), truncQ = 2, rm.phix = TRUE,
                          compress = TRUE, multithread = TRUE)
```

```{r}
head(filt.out)
```

#Learn Error Rates
```{r}
errF <- learnErrors(filtFs, multithread = TRUE)
errR <- learnErrors(filtRs, multithread = TRUE)
```

```{r}
plotErrors(errF, nominalQ = TRUE)
```

#Dereplication
```{r}
derepFs <- derepFastq(filtFs, verbose = TRUE)
derepRs <- derepFastq(filtRs, verbose = TRUE)
names(derepFs) <- sample.names
names(derepRs) <- sample.names
```

#Sample Inference
```{r}
dadaFs <- dada(derepFs, err=errF, multithread = TRUE)
dadaRs <- dada(derepRs, err=errR, multithread = TRUE)
```

```{r}
dadaFs[[2]]
```

#Merge Paired Reads
```{r}
mergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs, verbose = TRUE)
```

```{r}
head(mergers)
```

#Further Processing
Construct sequence table
```{r}
seqtab <- makeSequenceTable(mergers)
dim(seqtab)
```

```{r}
table(nchar(getSequences(seqtab)))
```

```{r}
seqtab2 <- seqtab[, nchar(colnames(seqtab)) %in% seq(,)]
```

Remove chimeras
```{r}
seqtab.nochim <- removeBimeraDenovo(seqtab2, method = "consensus", multithread = TRUE, verbose = TRUE)
dim(seqtab.nochim)
```

```{r}
sum(seqtab.nochim)/sum(seqtab2)
```

Track reads through the pipeline
```{r}
getN <- function(x) sum(getUniques(x))
filt.out %>%
  as_tibble(rownames = "filename") %>%
  mutate(sample = str_replace(filename, forward_fastq_suffix, "")) %>%
  select(sample, input = reads.in, filtered = reads.out) ->
  track

sapply(dadaFs, getN) %>%
  enframe(name = "sample", value = "denoised") ->
  denoised
track %<>% full_join(denoised, by = c("sample"))
```
